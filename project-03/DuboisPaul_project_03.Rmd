---
title: "Data Visualization for Exploratory Data Analysis"
output: html_document
---

# Data Visualization Project 03


In this exercise you will explore methods to create different types of data visualizations (such as plotting text data, or exploring the distributions of continuous variables).


## PART 1: Density Plots

Using the dataset obtained from FSU's [Florida Climate Center](https://climatecenter.fsu.edu/climate-data-access-tools/downloadable-data), for a station at Tampa International Airport (TPA) for 2022, attempt to recreate the charts shown below which were generated using data from 2016. You can read the 2022 dataset using the code below: 

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
weather_tpa <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/tpa_weather_2022.csv")
# random sample 
sample_n(weather_tpa, 4)
```

See https://www.reisanar.com/slides/relationships-models#10 for a reminder on how to use this type of dataset with the `lubridate` package for dates and times (example included in the slides uses data from 2016).

Using the 2022 data: 

(a) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_facet.png")
```

```{r}
# Create a count for each day of the temperature
weather_tpa %>% 
  mutate(monthName = month.name[month]) %>% 
  ggplot(mapping = aes(x = max_temp, fill = factor(monthName, levels = month.name))) +
  geom_histogram(color = "white", binwidth = 3) + 
  facet_wrap(~factor(monthName, levels = month.name), ncol = 3) +
  labs(
    x = "Maximum temperatures",
    y = "Number of Days"
  ) +
  scale_fill_viridis_d(name = "Temp. [F]", option = "D")+
  theme(
    legend.position = "none",
    axis.title.y = element_text(size = 15),
    axis.title.x = element_text(size = 15)
  )
```



Hint: the option `binwidth = 3` was used with the `geom_histogram()` function.

(b) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density.png")
```

```{r}
ggplot(data = weather_tpa, mapping = aes(max_temp)) + ## Why is the original graph starting at 50ish?
  geom_density(kernel = "epanechnikov", bw = 0.5, fill = "darkgray") ## Change color and kernel type
```


Hint: check the `kernel` parameter of the `geom_density()` function, and use `bw = 0.5`.

(c) Create a plot like the one below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density_facet.png")
```

Hint: default options for `geom_density()` were used. 

```{r}
weather_tpa %>% 
  mutate(monthName = month.name[month]) %>% 
  ggplot(mapping = aes(x = max_temp, fill = factor(monthName, levels = month.name))) + 
  geom_density(alpha = 0.5) +
  facet_wrap(~factor(monthName, levels = month.name), ncol = 3) +
  scale_fill_viridis_d(option = "D") +
  theme(
    legend.position = "none",
    axis.title.y = element_text(size = 15),
    axis.title.x = element_text(size = 15)
  )
```


(d) Generate a plot like the chart below:


```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_ridges_plasma.png")
```

Hint: use the`{ggridges}` package, and the `geom_density_ridges()` function paying close attention to the `quantile_lines` and `quantiles` parameters. The plot above uses the `plasma` option (color scale) for the _viridis_ palette.


```{r}
library(ggridges)
library(viridisLite)
weather_tpa %>% 
  mutate(monthName = month.name[month]) %>% 
  ggplot(mapping = aes(x = max_temp, y = factor(monthName, levels = month.name), fill = stat(x))) + 
    stat_density_ridges(geom = "density_ridges_gradient", quantile_lines = TRUE, quantiles = 2) +
    scale_fill_viridis_c(option = "C") +
  labs(
    x = "Maximum temperature (in Fahrenheit degrees",
    y = ""
  ) + 
  xlim(c(50,100)) +
  theme(
    legend.title = element_blank(),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(size = 18)
  )
  
```


(e) Create a plot of your choice that uses the attribute for precipitation _(values of -99.9 for temperature or -99.99 for precipitation represent missing data)_.

```{r}
weather_tpa %>% 
  mutate(monthName = month.name[month]) %>% 
  group_by(monthName) %>% 
  summarise(precip_avg = mean(precipitation)) %>% 
  ggplot(mapping = aes(x = factor(monthName, levels = month.name), y = precip_avg, color = precip_avg)) +
    geom_pointrange(mapping = aes(ymin = 0, ymax = precip_avg)) +
    geom_point(mapping = aes(size = precip_avg)) +
  scale_color_gradient(low = "#56b9ff", high = "#0a2859") +
  # scale_color_viridis_b(name = "", option = "", direction = -1) +
  labs(
    x = "",
    y = "Average Precipitation"
  ) +
  theme(
    legend.position = "none",
    axis.title.x = element_text(size = 15),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_text(size = 12)
  ) +
  coord_flip()
  
```
> I think a really cool idea would be to have a real looking bucket for each month, and have the amount of precipitation fill the bucket relative to other months and the amount of liquid the bucket can hold.

## PART 2 

> **You can choose to work on either Option (A) or Option (B)**. Remove from this template the option you decided not to work on. 


### Option (A): Visualizing Text Data

Review the set of slides (and additional resources linked in it) for visualizing text data: https://www.reisanar.com/slides/text-viz#1

Choose any dataset with text data, and create at least one visualization with it. For example, you can create a frequency count of most used bigrams, a sentiment analysis of the text data, a network visualization of terms commonly used together, and/or a visualization of a topic modeling approach to the problem of identifying words/documents associated to different topics in the text data you decide to use. 

Make sure to include a copy of the dataset in the `data/` folder, and reference your sources if different from the ones listed below:

- [Billboard Top 100 Lyrics](https://github.com/reisanar/datasets/blob/master/BB_top100_2015.csv)

- [RateMyProfessors comments](https://github.com/reisanar/datasets/blob/master/rmp_wit_comments.csv)

- [FL Poly News Articles](https://github.com/reisanar/datasets/blob/master/flpoly_news_SP23.csv)


(to get the "raw" data from any of the links listed above, simply click on the `raw` button of the GitHub page and copy the URL to be able to read it in your computer using the `read_csv()` function)


```{r}
library(wordcloud2)
library(tidytext)
poly_news <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/flpoly_news_SP23.csv")
```

```{r}
bigram_wcloud <- poly_news %>% 
  unnest_tokens(bigram, news_summary, token = "ngrams", n = 2) %>% 
  separate(bigram, c("word1", "word2"), sep = " ") %>% 
  filter(!word1 %in% stop_words$word) %>% # remove stopwords
  filter(!word2 %in% stop_words$word) %>% # remove stopwords
  unite(bigram, word1, word2, sep = " ") %>% 
  count(bigram, sort = TRUE) %>% 
  top_n(100)

set.seed(2006)
```


```{r}
set.seed(1)
wordcloud2(bigram_wcloud, size = 7, shuffle = 10)
```

